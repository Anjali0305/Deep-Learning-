{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DL (4) Churn_Modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber','CustomerId','Surname'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "       for column in df:\n",
    "                print(f'{column}: {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore: [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography: ['France' 'Spain' 'Germany']\n",
      "Gender: ['Female' 'Male']\n",
      "Age: [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure: [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance: [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts: [1 3 2 4]\n",
      "HasCrCard: [1 0]\n",
      "IsActiveMember: [1 0]\n",
      "EstimatedSalary: [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited: [1 0]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummies for geography and gender\n",
    "df = pd.get_dummies(data = df, columns=['Geography','Gender'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalling CreditScore, Age, Tenure, NumOfProducts, Balance, EstimatedSalary\n",
    "\n",
    "cols_to_scale = ['CreditScore', 'Age', 'Tenure', 'NumOfProducts', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore: [0.72823529 0.71529412 0.59058824 0.82235294 1.         0.75882353\n",
      " 0.96705882 0.44235294 0.58941176 0.80470588 0.62117647 0.58470588\n",
      " 0.56       0.64588235 0.74705882 0.72470588 0.76823529 0.69058824\n",
      " 0.85411765 0.86117647 0.74823529 0.6        0.78705882 0.99529412\n",
      " 0.67882353 0.88941176 0.67176471 0.67529412 0.48352941 0.69529412\n",
      " 0.62705882 0.65058824 0.61176471 0.84941176 0.55882353 0.57647059\n",
      " 0.94588235 0.68470588 0.55529412 0.54705882 0.65411765 0.98117647\n",
      " 0.77647059 0.91294118 0.97529412 0.74941176 0.64705882 0.82117647\n",
      " 0.68823529 0.92705882 0.77058824 0.70705882 0.77176471 0.85294118\n",
      " 0.60117647 0.72235294 0.87294118 0.80823529 0.65294118 0.70941176\n",
      " 0.88352941 0.68352941 0.86470588 0.77764706 0.79411765 0.86823529\n",
      " 0.95647059 0.77294118 0.71058824 0.61058824 0.78117647 0.79764706\n",
      " 0.89058824 0.48941176 0.78235294 0.91411765 0.63882353 0.59529412\n",
      " 0.58       0.76705882 0.88235294 0.85764706 0.76       0.76117647\n",
      " 0.95058824 0.61647059 0.90470588 0.85882353 0.60588235 0.90941176\n",
      " 0.95764706 0.83529412 0.48588235 0.73294118 0.78823529 0.73176471\n",
      " 0.92352941 0.71176471 0.56352941 0.80588235 0.63294118 0.66117647\n",
      " 0.84823529 0.73882353 0.78588235 0.97411765 0.79294118 0.73529412\n",
      " 0.50823529 0.90588235 0.89176471 0.93529412 0.80705882 0.92823529\n",
      " 0.69294118 0.54235294 0.68705882 0.68117647 0.78       0.80235294\n",
      " 0.93294118 0.81294118 0.57058824 0.76470588 0.88705882 0.62941176\n",
      " 0.84235294 0.63411765 0.83058824 0.68941176 0.74235294 0.84352941\n",
      " 0.94117647 0.80352941 0.82823529 0.72352941 0.78470588 0.56941176\n",
      " 0.56470588 0.68       0.60235294 0.71294118 0.70235294 0.91529412\n",
      " 0.60470588 0.61764706 0.84117647 0.68235294 0.94941176 0.61294118\n",
      " 0.89294118 0.60705882 0.83647059 0.72705882 0.75647059 0.78941176\n",
      " 0.81058824 0.72941176 0.79529412 0.67294118 0.81764706 0.69647059\n",
      " 0.66705882 0.81647059 0.64352941 0.69882353 0.79176471 0.71764706\n",
      " 0.90235294 0.89764706 0.83764706 0.82705882 0.77882353 0.77529412\n",
      " 0.61529412 0.90823529 0.64117647 0.74588235 0.86941176 0.90705882\n",
      " 0.80117647 0.64       0.81882353 0.90117647 0.85529412 0.81529412\n",
      " 0.65529412 0.62470588 0.58588235 0.76588235 0.93058824 0.86235294\n",
      " 0.95411765 0.83176471 0.84       0.92       0.91176471 0.94\n",
      " 0.70823529 0.87529412 0.69176471 0.87882353 0.68588235 0.73764706\n",
      " 0.86       0.74       0.51529412 0.75529412 0.94823529 0.55764706\n",
      " 0.65764706 0.50470588 0.8        0.88117647 0.86352941 0.75764706\n",
      " 0.73647059 0.76352941 0.94705882 0.84470588 0.98823529 0.74117647\n",
      " 0.76941176 0.89647059 0.66823529 0.72117647 0.61411765 0.86705882\n",
      " 0.76235294 0.52117647 0.75294118 0.63529412 0.54117647 0.69764706\n",
      " 0.94235294 0.71882353 0.94352941 0.87647059 0.56823529 0.81176471\n",
      " 0.57882353 0.83411765 0.82941176 0.65882353 0.88470588 0.82470588\n",
      " 0.63176471 0.57294118 0.70117647 0.82588235 0.57176471 0.85176471\n",
      " 0.64470588 0.54588235 0.92941176 0.62823529 0.88       0.58117647\n",
      " 0.69411765 0.55058824 0.59882353 0.96235294 0.96       0.63058824\n",
      " 0.88588235 0.91058824 0.73058824 0.66941176 0.77411765 0.93882353\n",
      " 0.75411765 0.63764706 0.81411765 0.75176471 0.9        0.67058824\n",
      " 0.75058824 0.70470588 0.74352941 0.91647059 0.62       0.66352941\n",
      " 0.98       0.59294118 0.99058824 0.59764706 0.49058824 0.70352941\n",
      " 0.87176471 0.71411765 0.89529412 0.99764706 0.64235294 0.51647059\n",
      " 0.88823529 0.89411765 0.61882353 0.83882353 0.82352941 0.78352941\n",
      " 0.66588235 0.58235294 0.80941176 0.72       0.56117647 0.50235294\n",
      " 0.98705882 0.96352941 0.84705882 0.54       0.59176471 0.73411765\n",
      " 0.62235294 0.66235294 0.56705882 0.93647059 0.52352941 0.87764706\n",
      " 0.92470588 0.65176471 0.79058824 0.92588235 0.58705882 0.99294118\n",
      " 0.52941176 0.95882353 0.98588235 0.94470588 0.86588235 0.74470588\n",
      " 0.70588235 0.79882353 0.60823529 0.93176471 0.87411765 0.57411765\n",
      " 0.49529412 0.98941176 0.83294118 0.59647059 0.59411765 0.53647059\n",
      " 0.51176471 0.66       0.60941176 0.66470588 0.85647059 0.92235294\n",
      " 0.64941176 0.71647059 0.89882353 0.82       0.85058824 0.64823529\n",
      " 0.52235294 0.84588235 0.58352941 0.63647059 0.97647059 0.95529412\n",
      " 0.79647059 0.49411765 0.7        0.72588235 0.95176471 0.58823529\n",
      " 0.97176471 0.51058824 0.60352941 0.56235294 0.93764706 0.42705882\n",
      " 0.46941176 0.54470588 0.91764706 0.53176471 0.67647059 0.98470588\n",
      " 0.93411765 0.96941176 0.50352941 0.96823529 0.91882353 0.99882353\n",
      " 0.57529412 0.50705882 0.53764706 0.90352941 0.97764706 0.42235294\n",
      " 0.96470588 0.67411765 0.67764706 0.65647059 0.96117647 0.52823529\n",
      " 0.51764706 0.48823529 0.96588235 0.62352941 0.41176471 0.52470588\n",
      " 0.5        0.87058824 0.56588235 0.92117647 0.42117647 0.99411765\n",
      " 0.53058824 0.53882353 0.55176471 0.49764706 0.47529412 0.98352941\n",
      " 0.55647059 0.98235294 0.54823529 0.57764706 0.41294118 0.97294118\n",
      " 0.99176471 0.42941176 0.62588235 0.48705882 0.53294118 0.55411765\n",
      " 0.47176471 0.95294118 0.97882353 0.55294118 0.52588235 0.49647059\n",
      " 0.97058824 0.50588235 0.51294118 0.50117647 0.48       0.99647059\n",
      " 0.49176471 0.51411765 0.48235294 0.53411765 0.47882353 0.53529412\n",
      " 0.54352941 0.45411765 0.47647059 0.45058824 0.46470588 0.54941176\n",
      " 0.50941176 0.52       0.49882353 0.52705882 0.51882353 0.43176471\n",
      " 0.48470588 0.44941176 0.43882353 0.49294118]\n",
      "Age: [0.45652174 0.44565217 0.42391304 0.4673913  0.47826087 0.54347826\n",
      " 0.31521739 0.29347826 0.33695652 0.26086957 0.36956522 0.27173913\n",
      " 0.38043478 0.48913043 0.63043478 0.34782609 0.41304348 0.5\n",
      " 0.39130435 0.35869565 0.43478261 0.55434783 0.66304348 0.5326087\n",
      " 0.40217391 0.20652174 0.7173913  0.60869565 0.2826087  0.22826087\n",
      " 0.59782609 0.81521739 0.23913043 0.32608696 0.30434783 0.70652174\n",
      " 0.52173913 0.56521739 0.61956522 0.79347826 0.51086957 0.58695652\n",
      " 0.7826087  0.2173913  0.72826087 0.85869565 0.67391304 0.57608696\n",
      " 0.86956522 0.64130435 0.73913043 0.25       0.65217391 0.76086957\n",
      " 0.68478261 0.69565217 0.19565217 0.89130435 0.75       0.80434783\n",
      " 0.77173913 0.82608696 0.83695652 0.95652174 0.92391304 0.91304348\n",
      " 0.84782609 0.88043478 1.         0.90217391]\n",
      "Tenure: [0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
      "Balance: [0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
      "NumOfProducts: [0.25 0.75 0.5  1.  ]\n",
      "HasCrCard: [1 0]\n",
      "IsActiveMember: [1 0]\n",
      "EstimatedSalary: [0.50676345 0.56273406 0.56967927 ... 0.21043581 0.46446006 0.19096108]\n",
      "Exited: [1 0]\n",
      "Geography_France: [1 0]\n",
      "Geography_Germany: [0 1]\n",
      "Geography_Spain: [0 1]\n",
      "Gender_Female: [1 0]\n",
      "Gender_Male: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis='columns')\n",
    "y = df['Exited']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 707us/step - loss: 0.5123 - accuracy: 0.7941\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4872 - accuracy: 0.7941\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 675us/step - loss: 0.4754 - accuracy: 0.7941\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.4699 - accuracy: 0.7940\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.4654 - accuracy: 0.79520s - loss: 0.4592 - accuracy: \n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 625us/step - loss: 0.4618 - accuracy: 0.7969\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4575 - accuracy: 0.7993\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.4525 - accuracy: 0.8005\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.4477 - accuracy: 0.8035\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.4420 - accuracy: 0.8043\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.4365 - accuracy: 0.8062\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 684us/step - loss: 0.4324 - accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 638us/step - loss: 0.4266 - accuracy: 0.8120\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4236 - accuracy: 0.8127\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.4200 - accuracy: 0.8142\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 606us/step - loss: 0.4159 - accuracy: 0.8163\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.4121 - accuracy: 0.8191\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.4082 - accuracy: 0.8219\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 605us/step - loss: 0.4045 - accuracy: 0.8255\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.3990 - accuracy: 0.8294\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3918 - accuracy: 0.8331\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.3861 - accuracy: 0.8354\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.3798 - accuracy: 0.8393\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.3769 - accuracy: 0.8409\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 656us/step - loss: 0.3734 - accuracy: 0.8435\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.3695 - accuracy: 0.8461\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.3669 - accuracy: 0.8459\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.3652 - accuracy: 0.8480\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 573us/step - loss: 0.3642 - accuracy: 0.8509\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 620us/step - loss: 0.3633 - accuracy: 0.8489\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 572us/step - loss: 0.3609 - accuracy: 0.8494\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.3606 - accuracy: 0.8514\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 638us/step - loss: 0.3587 - accuracy: 0.8512\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 637us/step - loss: 0.3572 - accuracy: 0.8518\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 652us/step - loss: 0.3566 - accuracy: 0.8522\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 621us/step - loss: 0.3559 - accuracy: 0.8516\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 571us/step - loss: 0.3545 - accuracy: 0.8525\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 656us/step - loss: 0.3551 - accuracy: 0.8535\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 567us/step - loss: 0.3544 - accuracy: 0.8536\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8551\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8565\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8535\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8553\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8536\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8555\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8545\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8554\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8539\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8561\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8576\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8545\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8566\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8558\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8568\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8579\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8561\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8595\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8568\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8566\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8561\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8579\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8580\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8561\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8579\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8594\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.8565\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8562\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8574\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8585\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8579\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8599\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8591\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8584\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8583\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8587\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8575\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8587\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8593\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8597\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8579\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8595\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8572\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8589\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8576\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8600\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8596\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8596\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8601\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8596\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8585\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8600\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8601\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8595\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8593\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8615\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8609\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8594\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8599\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8606\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db7b5f97f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(8, input_shape=(13,), activation = 'relu'),\n",
    "    keras.layers.Dense(5, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 625us/step - loss: 0.3396 - accuracy: 0.8645\n",
      "Loss -> 0.33960777521133423\n",
      "Accuracy -> 0.8644999861717224\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test,y_test)\n",
    "print('Loss ->', loss)\n",
    "print('Accuracy ->', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model.predict(X_test)\n",
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1610\n",
      "           1       0.75      0.46      0.57       390\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.82      0.71      0.74      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
